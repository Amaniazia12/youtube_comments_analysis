{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using naive bayes\n",
    "### Naive bayes\n",
    "The naive bayes algorithm depends on a simple probability theorem called bayes theorem that states\n",
    "\n",
    "The \"naive\" part in the name is a result of us treating each sentence in the data as independent from the other (no comment affects the other). This is not exactly true but is good enough for our purposes. Formally, we state this as (the data is iid \"independent and identically distributed\")\n",
    "\n",
    "### Our data\n",
    "To train our model, we will use a twitter sentiment dataset. This dataset consists of tweets and their correct sentiment ,positive or negative. It is made of around 100,000 tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we will read and observe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                      SentimentText  Sentiment  \\\n",
       "0          0  Bromwell High is a cartoon comedy. It ran at t...          1   \n",
       "1          1  Homelessness (or Houselessness as George Carli...          1   \n",
       "2          2  Brilliant over-acting by Lesley Ann Warren. Be...          1   \n",
       "3          3  This is easily the most underrated film inn th...          1   \n",
       "4          4  This is not the typical Mel Brooks film. It wa...          1   \n",
       "\n",
       "   Rating  \n",
       "0       9  \n",
       "1       8  \n",
       "2       0  \n",
       "3       7  \n",
       "4       8  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd_train = pd.read_csv(\"imbd_tr.csv\",index_col=False,names=[\"row_index\",\"SentimentText\",\"Sentiment\",\"Rating\"],header=0)\n",
    "print(pd_train.shape)\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_index                                      SentimentText  Sentiment  \\\n",
       "0          0  I went and saw this movie last night after bei...          1   \n",
       "1          1  Actor turned director Bill Paxton follows up h...          1   \n",
       "2          2  As a recreational golfer with some knowledge o...          1   \n",
       "3          3  I saw this film in a sneak preview, and it is ...          1   \n",
       "4          4  Bill Paxton has taken the true story of the 19...          1   \n",
       "\n",
       "   Rating  \n",
       "0       0  \n",
       "1       7  \n",
       "2       9  \n",
       "3       8  \n",
       "4       8  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test = pd.read_csv(\"imbd_te.csv\",index_col=False,names=[\"row_index\",\"SentimentText\",\"Sentiment\",\"Rating\"],header=0)\n",
    "print(pd_test.shape)\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we will preprocess the data by removing punctuation and converting the sentences in arrays of words. We will also shuffle the array to ensure that consecutive tweets are unrelated (iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [\".\",\",\",\":\",\"!\",\"?\",\"(\",\")\",\"/\",\";\",\"*\"]\n",
    "def preprocess(data):\n",
    "    preprocessed = []\n",
    "    for idx,row in enumerate(data[\"SentimentText\"]):\n",
    "        row = row.lower()\n",
    "        for punct in punctuation:\n",
    "            row = row.replace(punct,\"\")\n",
    "        preprocessed.append([row,data[\"Sentiment\"][idx]])\n",
    "    return preprocessed\n",
    "preprocessed_data = preprocess(pd_train)    \n",
    "\n",
    "train_data = [[row[0].split(),row[1]] for row in preprocessed_data]\n",
    "np.random.shuffle(train_data)\n",
    "\n",
    "classes = [0, 1] #For our data, we have only two classes (0 => negative and 1 => positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_test_data = preprocess(pd_test)    \n",
    "\n",
    "test_data = [[row[0].split(),row[1]] for row in preprocessed_test_data]\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_mult_naive_bayes(training_data, classes):\n",
    "    n_w_c = [0] * len(classes) # will contain the number of words in each class (ex: n_w_c[0] will be the number of words that were in documents that belong to class 0)\n",
    "    log_prior = [0] * len(classes) # will contain the priors for each class (ex: log_prior[0] = log P(class=0))\n",
    "    log_likelihood = [0] * len(classes) # will contain the log likelihood for each word given a class (ex: loglikelihood[0][\"good\"] is the log P(\"good\"|class=0))\n",
    "    documents_c = [[]] * len(classes) # will contain the document in each class (ex: documents_c[0] will contains all documents that are classified as class 0)\n",
    "    n_docs = len(training_data) # numbers of documents in the training data\n",
    "    Vocab = [] # a vocabulary of unique words\n",
    "    dictionaries = [{},{}] # will contains the number of occurences of a word in each class (ex: dictionaries[0][\"good\"] is the number of occurences of the word \"good\" in documents that belonged to class 0)\n",
    "    \n",
    "    # loop over all the training data\n",
    "    for review,parity in tqdm(training_data):\n",
    "        \n",
    "        # add this document to its correspoding class\n",
    "        documents_c[parity].append([review,parity])\n",
    "        \n",
    "        # add the number of words to n_w_c in the correct class\n",
    "        n_w_c[parity] += len(review)\n",
    "        \n",
    "        # loop over all words in the document and add the number of occurences to dictionaries. Also add unique words to Vocab\n",
    "        for word in review:\n",
    "            if word in dictionaries[parity]:\n",
    "                dictionaries[parity][word] += 1\n",
    "            else:\n",
    "                dictionaries[parity][word] = 1\n",
    "                \n",
    "            if word not in Vocab:\n",
    "                Vocab.append(word)\n",
    "  \n",
    "    \n",
    "    Vocab_size = len(Vocab)\n",
    "    n_w_c[0] += Vocab_size\n",
    "    n_w_c[1] += Vocab_size\n",
    "    \n",
    "    \n",
    "    # loop over all classes\n",
    "    for parity in range(len(classes)):\n",
    "        n_docs_in_class = len(documents_c[parity])\n",
    "        \n",
    "        log_prior[parity] = np.log((n_docs_in_class)/ n_docs)\n",
    "\n",
    "        denom = n_w_c[parity]\n",
    "\n",
    "        # loop over all unique words and calculate log_likelihoods for each word\n",
    "        for word in tqdm(Vocab):\n",
    "            if word in dictionaries[parity]:\n",
    "                dictionaries[parity][word] = np.log((dictionaries[parity][word])/denom)\n",
    "            else:\n",
    "                dictionaries[parity][word] = np.log(1.0/denom)\n",
    "        \n",
    "        log_likelihood[parity] = dictionaries[parity]\n",
    "        \n",
    "    return (Vocab, log_prior, log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 25000/25000 [17:53<00:00, 23.30it/s]\n",
      "100%|█████████████████████████████| 155010/155010 [00:00<00:00, 485074.23it/s]\n",
      "100%|█████████████████████████████| 155010/155010 [00:00<00:00, 459071.15it/s]\n"
     ]
    }
   ],
   "source": [
    "Vocab_,log_prior_,log_likelihood_ = train_mult_naive_bayes(train_data,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the accuracy of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2000/2000 [04:02<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 81.25 %\n"
     ]
    }
   ],
   "source": [
    "def test_mult_naive_bayes(review, classes, log_prior, log_likelihood, Vocab):\n",
    "    log_posteriors = [0] * len(classes)\n",
    "    \n",
    "    # loop over all classes and calculate the log_posterior for each\n",
    "    for c in classes:\n",
    "        sum_log_likelihoods = 0\n",
    "        \n",
    "        for word in review:\n",
    "            if word in Vocab:\n",
    "                sum_log_likelihoods += log_likelihood[c][word]\n",
    "        \n",
    "        log_posteriors[c] = log_prior[c] + sum_log_likelihoods\n",
    "    \n",
    "    # Find the class with the maximum log_posterior\n",
    "    max_log_posterior = max(log_posteriors)\n",
    "    argmax_log_posterior = log_posteriors.index(max_log_posterior)\n",
    "        \n",
    "    return classes[argmax_log_posterior]\n",
    "\n",
    "num_of_reviews_to_test = 2000\n",
    "correct_count = 0.0\n",
    "\n",
    "# loop over a number of test points = num_of_reviews_to_test and count the number of correctly classified ones\n",
    "for review,parity in tqdm(test_data[:num_of_reviews_to_test]):\n",
    "    pred = test_mult_naive_bayes(review,classes,log_prior_,log_likelihood_,Vocab_)\n",
    "    if pred == parity:\n",
    "        correct_count += 1\n",
    "\n",
    "# print the accuracy of the model\n",
    "accuracy = correct_count/num_of_reviews_to_test\n",
    "print(\"Test accuracy: {} %\".format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
